{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named librosa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1575e6445652>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## AUDIO DATA PROCESSING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named librosa"
     ]
    }
   ],
   "source": [
    "## AUDIO DATA PROCESSING\n",
    "import os\n",
    "import librosa\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension (the depth) is at index 1,\n",
    "in 'tf' mode is it at index 3. It defaults to the  image_dim_ordering value found in your\n",
    "Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"tf\".\n",
    "\n",
    "print K.image_dim_ordering()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 512\n",
    "work_dir = \"/media/ironman2/2230FAE530FABF3B/UrbanSound8K/audio\"\n",
    "\n",
    "## This for mel spectogram resolution\n",
    "n_bands = 60\n",
    "n_mfcc = 40\n",
    "n_frames = 40\n",
    "\n",
    "\n",
    "def windows(data, n_frames):\n",
    "    ws = window_size * (n_frames - 1)\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield start, start + ws, ws\n",
    "        start += (ws / 2)\n",
    "        ## OVERLAP OF 50%\n",
    "## END windows\n",
    "\n",
    "\n",
    "def extract_features():\n",
    "    raw_features = []\n",
    "    _labels = []\n",
    "\n",
    "    cnt = 0\n",
    "    for sub_dir in os.listdir(work_dir):\n",
    "        print(\"Working on dir: \", sub_dir)\n",
    "        if sub_dir=='.DS_Store': continue\n",
    "\n",
    "        for fs in os.listdir(work_dir + \"/\" + sub_dir):\n",
    "            if \".wav\" not in fs: continue\n",
    "            # print(\"Try Loading file: \", fs)\n",
    "            sound_clip, sr = librosa.load(work_dir + \"/\" + sub_dir + \"/\" + fs)\n",
    "            label = fs.split('-')[1]\n",
    "            print(cnt, \"Try Loading file: \", fs, \" class: \", label)\n",
    "            cnt += 1\n",
    "            ## Work of file bacthes\n",
    "            for (start, end, ws) in windows(sound_clip, n_frames):\n",
    "                ## Get the sound part\n",
    "                signal = sound_clip[start:end]\n",
    "                if len(signal) == ws:\n",
    "                    mfcc_spec = librosa.feature.mfcc(signal, n_mfcc=n_mfcc, n_mels=n_bands)\n",
    "                    mfcc_spec = mfcc_spec.T.flatten()[:, np.newaxis].T\n",
    "                    raw_features.append(mfcc_spec)\n",
    "                    _labels.append(label)\n",
    "\n",
    "    print(\"Loaded \", cnt, \" files\")\n",
    "    ## Add a new dimension\n",
    "    raw_features = np.asarray(raw_features).reshape(len(raw_features), n_mfcc, n_frames, 1)\n",
    "\n",
    "    ## Concate 2 elements on axis=3\n",
    "    _features = np.concatenate((raw_features, np.zeros(np.shape(raw_features))), axis=3)\n",
    "    _features = np.concatenate((_features, np.zeros(np.shape(raw_features))), axis=3)\n",
    "\n",
    "    for i in range(len(_features)):\n",
    "        _features[i, :, :, 1] = librosa.feature.delta(order=1, data=_features[i, :, :, 0])\n",
    "        _features[i, :, :, 2] = librosa.feature.delta(order=2, data=_features[i, :, :, 0])\n",
    "\n",
    "    return np.array(_features), np.array(_labels, dtype=np.int)\n",
    "## END extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = extract_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = open(\"data_x_librosa.pkl\", 'wb')\n",
    "pickle.dump(features, fd)\n",
    "fd2 = open(\"data_y_librosa.pkl\", 'wb')\n",
    "pickle.dump(labels, fd2)\n",
    "print('features and values saved...!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
